{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1230830-6d33-4bc5-bed2-a5a78de0520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import gc\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import dask\n",
    "import dask.array as da\n",
    "from dask import delayed, compute\n",
    "\n",
    "import cftime\n",
    "import pop_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db374225-72a9-4c11-9d41-657aad023f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "### INITIALISATION ###\n",
    "\n",
    "# Load data and group csv file by member\n",
    "filename = f\"change_point_indices_1.0_40_20.csv\"\n",
    "path = os.path.join(os.environ['HOME'], 'phase1_CONDA/publishable_code')\n",
    "file = os.path.join(path, filename)\n",
    "df = pd.read_csv(file)\n",
    "#####              #####\n",
    "##### INTERVENTION #####\n",
    "#####              #####\n",
    "df_first_three_rows = df.iloc[:3]\n",
    "df_first_three_rows = df_first_three_rows.groupby('Member')\n",
    "#####              #####\n",
    "##### INTERVENTION #####\n",
    "#####     END      #####\n",
    "#####              #####\n",
    "#grouped = df.groupby('Member')\n",
    "\n",
    "# Extract the variables from the filename\n",
    "filename = os.path.basename(file)\n",
    "parts = filename.replace('change_point_indices_', '').replace('.csv', '').split('_')\n",
    "threshold_multiple = float(parts[0])\n",
    "P1_len = int(parts[1])\n",
    "P2_len = int(parts[2])\n",
    "\n",
    "# set up mask\n",
    "grid_name = 'POP_gx1v7'\n",
    "region_defs = {\n",
    "    'subzero_Atlantic':[\n",
    "        {'match': {'REGION_MASK': [6]}, 'bounds': {'TLAT': [10.0, 70.0], 'TLONG': [260.0, 360.0]}}\n",
    "    ],\n",
    "    'superzero_Atlantic':[\n",
    "        {'match': {'REGION_MASK': [6]}, 'bounds': {'TLAT': [10.0, 70.0], 'TLONG': [0, 20.0]}}\n",
    "    ],\n",
    "    'Mediterranean': [\n",
    "        {'match': {'REGION_MASK': [7]}}\n",
    "    ],\n",
    "    'LabradorSea': [\n",
    "        {'match': {'REGION_MASK': [8]}, 'bounds': {'TLAT': [10.0, 70.0]}}\n",
    "    ],\n",
    "        'NordicSea': [\n",
    "        {'match': {'REGION_MASK': [9]}, 'bounds': {'TLAT': [10.0, 70.0]}}\n",
    "    ]\n",
    "}\n",
    "NA_mask = pop_tools.region_mask_3d(grid_name, region_defs=region_defs, mask_name='North Atlantic Mask')\n",
    "NA_mask = NA_mask.sum('region')\n",
    "NA_mask = NA_mask.roll(nlon=-100)\n",
    "\n",
    "# set up paths\n",
    "base_path = '/Data/gfi/share/ModData/CESM2_LENS2/ocean/monthly/'\n",
    "temporary_path = '/Data/skd/scratch/innag3580/comp/temporary/'\n",
    "final_path = '/Data/skd/scratch/innag3580/comp/composites/'\n",
    "\n",
    "# easy variables\n",
    "variables = ['TEMP', \n",
    "             'SALT', 'VVEL', 'SHF', 'HMXL', 'TAUX', 'TAUY']#, 'SIGMA_2']\n",
    "base_name = ['temp', \n",
    "             'salt', 'vvel', 'shf', 'hmxl', 'taux', 'tauy']#, 'dens']\n",
    "decrease_save_name = [f\"decrease_{name}_{threshold_multiple}_{P1_len}_{P2_len}.nc\" for name in base_name]\n",
    "increase_save_name = [f\"increase_{name}_{threshold_multiple}_{P1_len}_{P2_len}.nc\" for name in base_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d67d510e-407c-469f-b788-851aed363537",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### COMPUTATION ###\n",
    "\n",
    "#def standardise_time(ds):\n",
    "#####              #####\n",
    "##### INTERVENTION #####\n",
    "#####              #####\n",
    "def standardise_time(ds, time):\n",
    "    print('standardise_time start')\n",
    "    print(time.time())\n",
    "    print('')\n",
    "#####              #####\n",
    "##### INTERVENTION #####\n",
    "#####     END      #####\n",
    "#####              #####\n",
    "    ds['time'] = xr.decode_cf(ds, use_cftime=True).time\n",
    "    if isinstance(ds.time.values[0], cftime._cftime.DatetimeNoLeap):\n",
    "        time_as_datetime64 = np.array([pd.Timestamp(str(dt)).to_datetime64() for dt in ds.time.values])\n",
    "        ds['time'] = xr.DataArray(time_as_datetime64, dims='time')\n",
    "    return ds\n",
    "\n",
    "#def DJFM_average(ds):\n",
    "#####              #####\n",
    "##### INTERVENTION #####\n",
    "#####              #####\n",
    "def DJFM_average(ds, time):\n",
    "    print('DJFM_average start')\n",
    "    print(time.time())\n",
    "    print('')\n",
    "#####              #####\n",
    "##### INTERVENTION #####\n",
    "#####     END      #####\n",
    "#####              #####\n",
    "    ds_first_FM  = ds.isel(time=slice(0,2)).coarsen(time=2, boundary='trim').mean()\n",
    "    ds_DJFM = ds.isel(time=slice(2, None)).coarsen(time=4, boundary='trim').mean()\n",
    "    ds_combined = xr.concat([ds_first_FM, ds_DJFM], dim='time')\n",
    "    return ds_combined\n",
    "\n",
    "#def prepare_ds_member(var, member_id):\n",
    "#####              #####\n",
    "##### INTERVENTION #####\n",
    "#####              #####\n",
    "def prepare_ds_member(var, member_id, time):\n",
    "    print('prepare_ds_member start')\n",
    "    print(time.time())\n",
    "    print('')\n",
    "#####              #####\n",
    "##### INTERVENTION #####\n",
    "#####     END      #####\n",
    "#####              #####\n",
    "    file_pattern = os.path.join(base_path, var, f'*BHIST*LE2-{member_id}*.nc')\n",
    "    file_paths = sorted(glob.glob(file_pattern))\n",
    "    datasets = []\n",
    "    for file in file_paths:\n",
    "        ds_member = xr.open_dataset(file, chunks={'time': 12})\n",
    "        #ds_member = standardise_time(ds_member)\n",
    "        #####              #####\n",
    "        ##### INTERVENTION #####\n",
    "        #####              #####\n",
    "        ds_member = standardise_time(ds_member, time)\n",
    "        #####              #####\n",
    "        ##### INTERVENTION #####\n",
    "        #####     END      #####\n",
    "        #####              #####\n",
    "        \n",
    "        ds_member = ds_member.sel(time=ds_member['time.month'].isin([12, 1, 2, 3]))\n",
    "        datasets.append(ds_member)\n",
    "    #with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "    #    ds_member = xr.merge(datasets)\n",
    "    #    #ds_member = DJFM_average(ds_member)\n",
    "    #    #####              #####\n",
    "    #    ##### INTERVENTION #####\n",
    "    #    #####              #####\n",
    "    #    ds_member = DJFM_average(ds_member, time)\n",
    "    #    #####              #####\n",
    "    #    ##### INTERVENTION #####\n",
    "    #    #####     END      #####\n",
    "    #    #####              #####\n",
    "    \n",
    "    \n",
    "    #####              #####\n",
    "    ##### INTERVENTION #####\n",
    "    #####              #####\n",
    "    ds_member = xr.merge(datasets)\n",
    "    #ds_member = DJFM_average(ds_member)\n",
    "    #####              #####\n",
    "    ##### INTERVENTION #####\n",
    "    #####              #####\n",
    "    ds_member = DJFM_average(ds_member, time)\n",
    "    #####              #####\n",
    "    ##### INTERVENTION #####\n",
    "    #####     END      #####\n",
    "    #####              #####\n",
    "\n",
    "    #####              #####\n",
    "    ##### INTERVENTION #####\n",
    "    #####     END      #####\n",
    "    #####              #####\n",
    "    ds_member = ds_member.roll(nlon=-100).where(NA_mask == 1)\n",
    "    return ds_member   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ade1b0e-1a8d-4f50-b693-3069427398ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'TEMP'\n",
    "member_id = '1001.001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7c49ab01-50ee-4a2c-a0d8-576ad0b30052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise_time(ds):\n",
    "    ds['time'] = xr.decode_cf(ds, use_cftime=True).time\n",
    "    if isinstance(ds.time.values[0], cftime._cftime.DatetimeNoLeap):\n",
    "        time_as_datetime64 = np.array([pd.Timestamp(str(dt)).to_datetime64() for dt in ds.time.values])\n",
    "        ds['time'] = xr.DataArray(time_as_datetime64, dims='time')\n",
    "    return ds\n",
    "\n",
    "def DJFM_average(ds):\n",
    "    numeric_vars = {k: v for k, v in ds.data_vars.items() if np.issubdtype(v.dtype, np.number)}\n",
    "    ds_numeric = xr.Dataset(numeric_vars, coords=ds.coords)\n",
    "    \n",
    "    ds_first_FM  = ds_numeric.isel(time=slice(0,2)).coarsen(time=2, boundary='trim').mean()\n",
    "    ds_DJFM = ds_numeric.isel(time=slice(2, None)).coarsen(time=4, boundary='trim').mean()\n",
    "    ds_combined = xr.concat([ds_first_FM, ds_DJFM], dim='time')\n",
    "    return ds_combined\n",
    "\n",
    "def prepare_ds_member(var, member_id):\n",
    "    print('prepare_ds_member start')\n",
    "    print('')\n",
    "    file_pattern = os.path.join(base_path, var, f'*BHIST*LE2-{member_id}*.nc')\n",
    "    file_paths = sorted(glob.glob(file_pattern))\n",
    "    \n",
    "    ds_member = xr.open_mfdataset(file_paths, chunks={'time': 120}, preprocess=standardise_time)\n",
    "\n",
    "    ds_member = ds_member.sel(time=ds_member['time.month'].isin([12, 1, 2, 3]))\n",
    "    ds_member = DJFM_average(ds_member)\n",
    "    ds_member = ds_member.roll(nlon=-100).where(NA_mask == 1)\n",
    "    \n",
    "    return ds_member "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "149990ba-4849-4618-bf11-b2de8f4cdba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare_ds_member start\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/innag3580/.conda/envs/movie/lib/python3.10/site-packages/xarray/core/indexing.py:1374: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/tmp/ipykernel_235274/1875693074.py:13: PerformanceWarning: Reshaping is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array.reshape(shape)\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array.reshape(shape)Explictly passing ``limit`` to ``reshape`` will also silence this warning\n",
      "    >>> array.reshape(shape, limit='128 MiB')\n",
      "  ds_DJFM = ds_numeric.isel(time=slice(2, None)).coarsen(time=4, boundary='trim').mean()\n"
     ]
    }
   ],
   "source": [
    "ds_member = prepare_ds_member(var, member_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3020651-d421-4f1a-a29c-2b50d316ca6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
